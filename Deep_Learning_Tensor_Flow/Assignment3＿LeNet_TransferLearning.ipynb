{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hsing-Yi Wang\n",
    "### 1. Train LeNet with MNIST dataset and random initialization and store the weights by using tf.train.Saver()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import numpy\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow.contrib.layers import flatten\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8    ...     pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
       "0       0    ...            0         0         0         0         0   \n",
       "1       0    ...            0         0         0         0         0   \n",
       "2       0    ...            0         0         0         0         0   \n",
       "3       0    ...            0         0         0         0         0   \n",
       "4       0    ...            0         0         0         0         0   \n",
       "\n",
       "   pixel779  pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0         0  \n",
       "1         0         0         0         0         0  \n",
       "2         0         0         0         0         0  \n",
       "3         0         0         0         0         0  \n",
       "4         0         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('/Users/eve7947/digit-recognizer/train.csv')\n",
    "df_test = pd.read_csv('/Users/eve7947/digit-recognizer/test.csv')\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 784)\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.get_dummies(df_train,columns=['label'])\n",
    "df_features = df_train.iloc[:, :-10].values\n",
    "df_label = df_train.iloc[:, -10:].values\n",
    "print(df_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_features, df_label, test_size = 0.2, random_state = 1212)\n",
    "X_test, X_validation, y_test,y_validation = train_test_split(X_test, y_test, test_size=0.5, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set : (33600, 28, 28, 1) (33600, 1, 10)\n",
      "Validation set : (4200, 28, 28, 1) (4200, 1, 10)\n",
      "Test set : (4200, 28, 28, 1) (4200, 1, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eve7947/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:12: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "#Re-shape the data format into 28x28x1\n",
    "image_size = 28\n",
    "num_labels = 10\n",
    "num_channels = 1 # grayscale\n",
    "def reformat(dataset, labels):\n",
    " dataset = dataset.reshape((-1, image_size, image_size, num_channels)).astype(np.float32)\n",
    " labels = (np.arange(num_labels) == labels[:,None]).astype(np.float32)\n",
    " return dataset, labels\n",
    "train_dataset, train_labels = reformat(X_train, y_train)\n",
    "valid_dataset, valid_labels = reformat(X_validation, y_validation)\n",
    "test_dataset , test_labels = reformat(X_test, y_test)\n",
    "df_test = df_test.as_matrix().reshape((-1, image_size, image_size, num_channels)).astype(np.float32)\n",
    "print ('Training set :', train_dataset.shape, train_labels.shape)\n",
    "print ('Validation set :', valid_dataset.shape, valid_labels.shape)\n",
    "print ('Test set :', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set after padding 2x2    : (33600, 32, 32, 1) (33600, 1, 10)\n",
      "Validation set after padding 2x2  : (4200, 32, 32, 1) (4200, 1, 10)\n",
      "Test set after padding 2x2        : (4200, 32, 32, 1) (4200, 1, 10)\n",
      "Submission data after padding 2x2 : (4200, 32, 32, 1)\n"
     ]
    }
   ],
   "source": [
    "# Pad images with 0s\n",
    "X_train      = np.pad(train_dataset, ((0,0),(2,2),(2,2),(0,0)), 'constant')\n",
    "X_validation = np.pad(valid_dataset, ((0,0),(2,2),(2,2),(0,0)), 'constant')\n",
    "X_test       = np.pad(test_dataset, ((0,0),(2,2),(2,2),(0,0)), 'constant')\n",
    "    \n",
    "print ('Training set after padding 2x2    :', X_train.shape, train_labels.shape)\n",
    "print ('Validation set after padding 2x2  :', X_validation.shape, valid_labels.shape)\n",
    "print ('Test set after padding 2x2        :', X_test.shape, test_labels.shape)\n",
    "print ('Submission data after padding 2x2 :', X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LeNet-5 architecture implementation using TensorFlow\n",
    "def LeNet_5(x):\n",
    " \n",
    " # Layer 1 : Convolutional Layer. Input = 32x32x1, Output = 28x28x1.\n",
    " conv1_w = tf.Variable(tf.truncated_normal(shape = [5,5,1,6],mean = 0, stddev = 0.1))\n",
    " conv1_b = tf.Variable(tf.zeros(6))\n",
    " conv1 = tf.nn.conv2d(x,conv1_w, strides = [1,1,1,1], padding = 'VALID') + conv1_b \n",
    " # TODO: Activation.\n",
    " conv1 = tf.nn.relu(conv1)\n",
    " \n",
    " # Pooling Layer. Input = 28x28x1. Output = 14x14x6.\n",
    " pool_1 = tf.nn.max_pool(conv1, ksize = [1,2,2,1], strides = [1,2,2,1], padding = 'VALID')\n",
    " \n",
    " \n",
    " # TODO: Layer 2: Convolutional. Output = 10x10x16.\n",
    " conv2_w = tf.Variable(tf.truncated_normal(shape = [5,5,6,16], mean = 0, stddev = 0.1))\n",
    " conv2_b = tf.Variable(tf.zeros(16))\n",
    " conv2 = tf.nn.conv2d(pool_1, conv2_w, strides = [1,1,1,1], padding = 'VALID') + conv2_b\n",
    " # TODO: Activation.\n",
    " conv2 = tf.nn.relu(conv2)\n",
    "# TODO: Pooling. Input = 10x10x16. Output = 5x5x16.\n",
    " pool_2 = tf.nn.max_pool(conv2, ksize = [1,2,2,1], strides = [1,2,2,1], padding = 'VALID')\n",
    " \n",
    " \n",
    " # TODO: Flatten. Input = 5x5x16. Output = 400.\n",
    " fc1 = flatten(pool_2)\n",
    " \n",
    " \n",
    " # TODO: Layer 3: Fully Connected. Input = 400. Output = 120.\n",
    " fc1_w = tf.Variable(tf.truncated_normal(shape = (400,120), mean = 0, stddev = 0.1))\n",
    " fc1_b = tf.Variable(tf.zeros(120))\n",
    " fc1 = tf.matmul(fc1,fc1_w) + fc1_b\n",
    " \n",
    " # TODO: Activation.\n",
    " fc1 = tf.nn.relu(fc1)\n",
    " \n",
    " # TODO: Layer 4: Fully Connected. Input = 120. Output = 84.\n",
    " fc2_w = tf.Variable(tf.truncated_normal(shape = (120,84), mean = 0, stddev = 0.1))\n",
    " fc2_b = tf.Variable(tf.zeros(84))\n",
    " fc2 = tf.matmul(fc1,fc2_w) + fc2_b\n",
    " # TODO: Activation.\n",
    " fc2 = tf.nn.relu(fc2)\n",
    " \n",
    " # TODO: Layer 5: Fully Connected. Input = 84. Output = 10.\n",
    " fc3_w = tf.Variable(tf.truncated_normal(shape = (84,10), mean = 0 , stddev = 0.1))\n",
    " fc3_b = tf.Variable(tf.zeros(10))\n",
    " logits = tf.matmul(fc2, fc3_w) + fc3_b\n",
    " return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None,32,32,1])\n",
    "y_ = tf.placeholder(tf.int32, (None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/eve7947/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /Users/eve7947/anaconda3/lib/python3.7/site-packages/tensorflow/contrib/layers/python/layers/layers.py:1624: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n"
     ]
    }
   ],
   "source": [
    "#Invoke LeNet function by passing features\n",
    "logits = LeNet_5(x)\n",
    "#Softmax with cost function implementation\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits_v2(labels = y_, logits = logits)\n",
    "loss_operation = tf.reduce_mean(cross_entropy)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = 0.001)\n",
    "training_operation = optimizer.minimize(loss_operation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(logits,1), tf.argmax(y_,1))\n",
    "accuracy_operation = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "# Evaluate function\n",
    "def evaluate(X_data, y_data):\n",
    " num_examples = len(X_data)\n",
    " total_accuracy = 0\n",
    " sess = tf.get_default_session()\n",
    " for offset in range(0, num_examples, BATCH_SIZE):\n",
    "        batch_x, batch_y = X_data[offset:offset+BATCH_SIZE], y_data[offset:offset+BATCH_SIZE]\n",
    "        accuracy = sess.run(accuracy_operation, feed_dict={x: batch_x, y_: batch_y})\n",
    "        total_accuracy += (accuracy * len(batch_x))\n",
    " return total_accuracy / num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training... with dataset -  33600\n",
      "\n",
      "EPOCH 1 ...\n",
      "Validation Accuracy = 0.943\n",
      "\n",
      "EPOCH 2 ...\n",
      "Validation Accuracy = 0.963\n",
      "\n",
      "EPOCH 3 ...\n",
      "Validation Accuracy = 0.973\n",
      "\n",
      "EPOCH 4 ...\n",
      "Validation Accuracy = 0.978\n",
      "\n",
      "EPOCH 5 ...\n",
      "Validation Accuracy = 0.977\n",
      "\n",
      "EPOCH 6 ...\n",
      "Validation Accuracy = 0.979\n",
      "\n",
      "EPOCH 7 ...\n",
      "Validation Accuracy = 0.978\n",
      "\n",
      "EPOCH 8 ...\n",
      "Validation Accuracy = 0.980\n",
      "\n",
      "EPOCH 9 ...\n",
      "Validation Accuracy = 0.980\n",
      "\n",
      "EPOCH 10 ...\n",
      "Validation Accuracy = 0.981\n",
      "\n",
      "Test Accuracy = 0.979\n"
     ]
    }
   ],
   "source": [
    "#To initialise session and run\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    num_examples = len(X_train)\n",
    "    \n",
    "    print(\"Training... with dataset - \", num_examples)\n",
    "    print()\n",
    "    for i in range(EPOCHS):\n",
    "        X_train, y_train = shuffle(X_train, y_train)\n",
    "        for offset in range(0, num_examples, BATCH_SIZE):\n",
    "            end = offset + BATCH_SIZE\n",
    "            batch_x, batch_y = X_train[offset:end], y_train[offset:end]\n",
    "            sess.run(training_operation, feed_dict={x: batch_x, y_: batch_y})\n",
    "            \n",
    "        validation_accuracy = evaluate(X_validation, y_validation)\n",
    "        print(\"EPOCH {} ...\".format(i+1))\n",
    "        print(\"Validation Accuracy = {:.3f}\".format(validation_accuracy))\n",
    "        print()\n",
    "    \n",
    "    saver.save(sess, '/tmp/lenet.ckpt')    \n",
    "    test_accuracy = evaluate(X_test, y_test)\n",
    "    print(\"Test Accuracy = {:.3f}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  2. Retrieve the saved weights and use them to train Fashion MNIST data set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-13-3cac52ed4b32>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /Users/eve7947/anaconda3/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /Users/eve7947/anaconda3/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting data/fashion/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/eve7947/anaconda3/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting data/fashion/train-labels-idx1-ubyte.gz\n",
      "Extracting data/fashion/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/fashion/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/eve7947/anaconda3/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "data = input_data.read_data_sets('data/fashion', source_url='http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(image_file, label_file, output_file, samples):\n",
    "    input_images = open(image_file, \"rb\")\n",
    "    input_labels = open(label_file, \"rb\")\n",
    "    output = open(output_file, \"w\")\n",
    " \n",
    "    input_images.read(16)\n",
    "    input_labels.read(8)\n",
    "    images = []\n",
    " \n",
    "    for i in range(samples):\n",
    "        image = [ord(input_labels.read(1))]\n",
    " \n",
    "        for j in range(28*28):\n",
    "            image.append(ord(input_images.read(1)))\n",
    " \n",
    "        images.append(image)\n",
    " \n",
    "    for image in images:\n",
    "        output.write(\",\".join(str(pixel) for pixel in image) + \"\\n\")\n",
    " \n",
    "    input_images.close()\n",
    "    input_labels.close()\n",
    "    output.close()\n",
    " \n",
    " \n",
    "process(\"/Users/eve7947/ucsc-coursework/Deep_Learning_Tensor_Flow/data/fashion/train-images-idx3-ubyte\",\n",
    "        \"/Users/eve7947/ucsc-coursework/Deep_Learning_Tensor_Flow/data/fashion/train-labels-idx1-ubyte\", \"mnist-train-data.csv\", 60000)\n",
    " \n",
    "process(\"/Users/eve7947/ucsc-coursework/Deep_Learning_Tensor_Flow/data/fashion/t10k-images-idx3-ubyte\",\n",
    "        \"/Users/eve7947/ucsc-coursework/Deep_Learning_Tensor_Flow/data/fashion/t10k-labels-idx1-ubyte\", \"mnist-test-data.csv\", 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>775</th>\n",
       "      <th>776</th>\n",
       "      <th>777</th>\n",
       "      <th>778</th>\n",
       "      <th>779</th>\n",
       "      <th>780</th>\n",
       "      <th>781</th>\n",
       "      <th>782</th>\n",
       "      <th>783</th>\n",
       "      <th>784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>119</td>\n",
       "      <td>114</td>\n",
       "      <td>130</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1    2    3    4    5    6    7    8    9   ...   775  776  777  778  \\\n",
       "0    9    0    0    0    0    0    0    0    0    0 ...     0    0    0    0   \n",
       "1    0    0    0    0    0    0    1    0    0    0 ...   119  114  130   76   \n",
       "2    0    0    0    0    0    0    0    0    0    0 ...     0    0    1    0   \n",
       "3    3    0    0    0    0    0    0    0    0   33 ...     0    0    0    0   \n",
       "4    0    0    0    0    0    0    0    0    0    0 ...     0    0    0    0   \n",
       "\n",
       "   779  780  781  782  783  784  \n",
       "0    0    0    0    0    0    0  \n",
       "1    0    0    0    0    0    0  \n",
       "2    0    0    0    0    0    0  \n",
       "3    0    0    0    0    0    0  \n",
       "4    0    0    0    0    0    0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2_train = pd.read_csv('/Users/eve7947/ucsc-coursework/Deep_Learning_Tensor_Flow/mnist-train-data.csv', header = None)\n",
    "df2_test = pd.read_csv('/Users/eve7947/ucsc-coursework/Deep_Learning_Tensor_Flow/mnist-test-data.csv', header = None)\n",
    "df2_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get length of df's columns\n",
    "num_cols = len(list(df2_train))\n",
    "\n",
    "# generate range of ints for suffixes\n",
    "# with length exactly half that of num_cols;\n",
    "# if num_cols is even, truncate concatenated list later\n",
    "# to get to original list length\n",
    "rng = range(1, (num_cols // 2) + 1)\n",
    "\n",
    "new_cols = ['Name'] + ['type_' + str(i) for i in rng] + ['expt_' + str(i) for i in rng]\n",
    "\n",
    "# ensure the length of the new columns list is equal to the length of df's columns\n",
    "df2_train.columns = new_cols[:num_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>type_1</th>\n",
       "      <th>type_2</th>\n",
       "      <th>type_3</th>\n",
       "      <th>type_4</th>\n",
       "      <th>type_5</th>\n",
       "      <th>type_6</th>\n",
       "      <th>type_7</th>\n",
       "      <th>type_8</th>\n",
       "      <th>type_9</th>\n",
       "      <th>...</th>\n",
       "      <th>expt_383</th>\n",
       "      <th>expt_384</th>\n",
       "      <th>expt_385</th>\n",
       "      <th>expt_386</th>\n",
       "      <th>expt_387</th>\n",
       "      <th>expt_388</th>\n",
       "      <th>expt_389</th>\n",
       "      <th>expt_390</th>\n",
       "      <th>expt_391</th>\n",
       "      <th>expt_392</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>119</td>\n",
       "      <td>114</td>\n",
       "      <td>130</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Name  type_1  type_2  type_3  type_4  type_5  type_6  type_7  type_8  \\\n",
       "0     9       0       0       0       0       0       0       0       0   \n",
       "1     0       0       0       0       0       0       1       0       0   \n",
       "2     0       0       0       0       0       0       0       0       0   \n",
       "3     3       0       0       0       0       0       0       0       0   \n",
       "4     0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   type_9    ...     expt_383  expt_384  expt_385  expt_386  expt_387  \\\n",
       "0       0    ...            0         0         0         0         0   \n",
       "1       0    ...          119       114       130        76         0   \n",
       "2       0    ...            0         0         1         0         0   \n",
       "3      33    ...            0         0         0         0         0   \n",
       "4       0    ...            0         0         0         0         0   \n",
       "\n",
       "   expt_388  expt_389  expt_390  expt_391  expt_392  \n",
       "0         0         0         0         0         0  \n",
       "1         0         0         0         0         0  \n",
       "2         0         0         0         0         0  \n",
       "3         0         0         0         0         0  \n",
       "4         0         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n"
     ]
    }
   ],
   "source": [
    "df2_train = pd.get_dummies(df2_train,columns=['Name'])\n",
    "df2_features = df2_train.iloc[:, :-10].values\n",
    "df2_label = df2_train.iloc[:, -10:].values\n",
    "print(df2_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2_train, X2_test, y2_train, y2_test = train_test_split(df2_features, df2_label, test_size = 0.2, random_state = 1212)\n",
    "X2_test, X2_validation, y2_test,y2_validation = train_test_split(X2_test, y2_test, test_size=0.5, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set : (48000, 28, 28, 1) (48000, 1, 10)\n",
      "Validation set : (6000, 28, 28, 1) (6000, 1, 10)\n",
      "Test set : (6000, 28, 28, 1) (6000, 1, 10)\n"
     ]
    }
   ],
   "source": [
    "#Re-shape the data format into 28x28x1\n",
    "image_size = 28\n",
    "num_labels = 10\n",
    "num_channels = 1 # grayscale\n",
    "train2_dataset, train2_labels = reformat(X2_train, y2_train)\n",
    "valid2_dataset, valid2_labels = reformat(X2_validation, y2_validation)\n",
    "test2_dataset , test2_labels = reformat(X2_test, y2_test)\n",
    "#df2_test = df2_test.as_matrix().reshape((-1, image_size, image_size, num_channels)).astype(np.float32)\n",
    "print ('Training set :', train2_dataset.shape, train2_labels.shape)\n",
    "print ('Validation set :', valid2_dataset.shape, valid2_labels.shape)\n",
    "print ('Test set :', test2_dataset.shape, test2_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set after padding 2x2    : (33600, 32, 32, 1) (33600, 1, 10)\n",
      "Validation set after padding 2x2  : (4200, 32, 32, 1) (4200, 1, 10)\n",
      "Test set after padding 2x2        : (4200, 32, 32, 1) (4200, 1, 10)\n",
      "Submission data after padding 2x2 : (4200, 32, 32, 1)\n"
     ]
    }
   ],
   "source": [
    "X2_train      = np.pad(train2_dataset, ((0,0),(2,2),(2,2),(0,0)), 'constant')\n",
    "X2_validation = np.pad(valid2_dataset, ((0,0),(2,2),(2,2),(0,0)), 'constant')\n",
    "X2_test       = np.pad(test2_dataset, ((0,0),(2,2),(2,2),(0,0)), 'constant')\n",
    "\n",
    "print ('Training set after padding 2x2    :', X_train.shape, train_labels.shape)\n",
    "print ('Validation set after padding 2x2  :', X_validation.shape, valid_labels.shape)\n",
    "print ('Test set after padding 2x2        :', X_test.shape, test_labels.shape)\n",
    "print ('Submission data after padding 2x2 :', X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "restoring from /tmp/lenet.ckpt\n",
      "WARNING:tensorflow:From /Users/eve7947/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/lenet.ckpt\n",
      "Training... with dataset -  33600\n",
      "\n",
      "EPOCH 1 ...\n",
      "Validation Accuracy = 0.976\n",
      "\n",
      "EPOCH 2 ...\n",
      "Validation Accuracy = 0.981\n",
      "\n",
      "EPOCH 3 ...\n",
      "Validation Accuracy = 0.981\n",
      "\n",
      "EPOCH 4 ...\n",
      "Validation Accuracy = 0.979\n",
      "\n",
      "EPOCH 5 ...\n",
      "Validation Accuracy = 0.984\n",
      "\n",
      "EPOCH 6 ...\n",
      "Validation Accuracy = 0.981\n",
      "\n",
      "EPOCH 7 ...\n",
      "Validation Accuracy = 0.981\n",
      "\n",
      "EPOCH 8 ...\n",
      "Validation Accuracy = 0.982\n",
      "\n",
      "EPOCH 9 ...\n",
      "Validation Accuracy = 0.982\n",
      "\n",
      "EPOCH 10 ...\n",
      "Validation Accuracy = 0.982\n",
      "\n",
      "Test Accuracy = 0.983\n"
     ]
    }
   ],
   "source": [
    "tf.set_random_seed(123445)\n",
    "digits_fashion = True\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    if digits_fashion:\n",
    "        print('restoring from /tmp/lenet.ckpt')\n",
    "        saver.restore(sess, '/tmp/lenet.ckpt')\n",
    "    else:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    num_examples = len(X_train)\n",
    "    \n",
    "    print(\"Training... with dataset - \", num_examples)\n",
    "    print()\n",
    "    for i in range(EPOCHS):\n",
    "        X_train, y_train = shuffle(X_train, y_train)\n",
    "        for offset in range(0, num_examples, BATCH_SIZE):\n",
    "            end = offset + BATCH_SIZE\n",
    "            batch_x, batch_y = X_train[offset:end], y_train[offset:end]\n",
    "            sess.run(training_operation, feed_dict={x: batch_x, y_: batch_y})\n",
    "            \n",
    "        validation_accuracy = evaluate(X_validation, y_validation)\n",
    "        print(\"EPOCH {} ...\".format(i+1))\n",
    "        print(\"Validation Accuracy = {:.3f}\".format(validation_accuracy))\n",
    "        print()\n",
    "     \n",
    "    test_accuracy = evaluate(X_test, y_test)\n",
    "    print(\"Test Accuracy = {:.3f}\".format(test_accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
